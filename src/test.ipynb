{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d442606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import outlines\n",
    "from outlines.types.dsl import Regex, String, at_most, either, to_regex\n",
    "from outlines.types import zero_or_more, one_or_more, optional, whitespace, digit\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic_evals import Dataset\n",
    "from pydantic_evals.evaluators import Evaluator, EvaluatorContext\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from m_gsm_symbolic.kaenguruen.load_data import load_kaenguruen\n",
    "from m_gsm_symbolic.load_data import load_gsm_dan, load_gsm_eng\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ab570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58e0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#load_dotenv()\n",
    "#api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "from huggingface_hub import login\n",
    "#login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5dc05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#judge_llm_name = \"openai:gpt-4o-2024-08-06\"\n",
    "response_model_name = \"meta-llama/Llama-3.2-1B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Outlines regex DSL: reasoning (any text) + '####' + answer (int)\n",
    "answer_pattern = to_regex(\n",
    "    Regex(pattern=r\".\").at_most(500) +\n",
    "    String(\"#### \") +\n",
    "    digit.one_or_more() +\n",
    "    optional(\n",
    "        either(\n",
    "            String(\".\"), String(\",\")\n",
    "        ) + optional(\n",
    "            digit.one_or_more()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# Support float or frac as well\n",
    "    #sequence(\n",
    "    #    one_or_more(digit()),\n",
    "    #    optional(either(\n",
    "    #        sequence(literal(\".\"), one_or_more(digit())),\n",
    "    #        sequence(literal(\"/\"), one_or_more(digit()))\n",
    "    #    ))\n",
    "    #)\n",
    "\n",
    "class HuggingFaceAgent:\n",
    "    def __init__(self, model: str, examples: list, \n",
    "                 answer_pattern: Regex = answer_pattern):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.model = outlines.from_transformers(AutoModelForCausalLM.from_pretrained(model, torch_dtype=\"auto\"), self.tokenizer).to(device)\n",
    "        self.cases = examples\n",
    "        self.answer_pattern = answer_pattern\n",
    "\n",
    "    def _build_prompt(self, prompt):\n",
    "        examples = []\n",
    "        for case in self.cases:\n",
    "            example = f\"Problem: {case.inputs}\\n\\nSolution: {case.expected_output}\"\n",
    "            examples.append(example)\n",
    "\n",
    "        prompt = f\"Problem: {prompt}\\n\\nSolution:\"\n",
    "        examples.append(prompt)\n",
    "        prompt = \"\\n\\n\".join(examples)\n",
    "        return prompt\n",
    "\n",
    "    def run(self, prompt: str):\n",
    "        prompt = self._build_prompt(prompt)\n",
    "\n",
    "        model_output = self.model(prompt, answer_pattern, max_new_tokens=500)\n",
    "        return model_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0143d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 0: 40\n",
      "Case 1: 58\n",
      "Case 2: 30\n",
      "Case 3: 38\n",
      "Case 4: 56\n",
      "Case 5: 4\n",
      "Case 6: 18\n",
      "Case 7: 54\n",
      "Case 8: 210\n",
      "Case 9: 1050\n",
      "Case 10: 8\n",
      "Case 11: 4\n",
      "Case 12: 5\n",
      "Case 13: 55\n",
      "Case 14: 2\n",
      "Case 15: 11\n",
      "Case 16: 77\n",
      "Case 17: 118000\n",
      "Case 18: 16\n",
      "Case 19: 540\n",
      "Case 20: 35\n",
      "Case 21: 43200\n",
      "Case 22: 64\n",
      "Case 23: 12\n",
      "Case 24: 88\n",
      "Case 25: 10\n",
      "Case 26: 130\n",
      "Case 27: 342\n",
      "Case 28: 70\n",
      "Case 29: 320\n",
      "Case 30: 157\n",
      "Case 31: 2\n",
      "Case 32: 25\n",
      "Case 33: 72\n",
      "Case 34: 75\n",
      "Case 35: 140\n",
      "Case 36: 16\n",
      "Case 37: 14400\n",
      "Case 38: 2\n",
      "Case 39: 3200\n",
      "Case 40: 100\n",
      "Case 41: 5\n",
      "Case 42: 14\n",
      "Case 43: 4\n",
      "Case 44: 63\n",
      "Case 45: 2\n",
      "Case 46: 15\n",
      "Case 47: 200\n",
      "Case 48: 4\n",
      "Case 49: 694\n",
      "Case 50: 4000\n",
      "Case 51: 6\n",
      "Case 52: 9\n",
      "Case 53: 159\n",
      "Case 54: 48\n",
      "Case 55: 45\n",
      "Case 56: 100\n",
      "Case 57: 3\n",
      "Case 58: 42\n",
      "Case 59: 48\n",
      "Case 60: 428\n",
      "Case 61: 25\n",
      "Case 62: 75\n",
      "Case 63: 10\n",
      "Case 64: 3430\n",
      "Case 65: 18\n",
      "Case 66: 78\n",
      "Case 67: 16\n",
      "Case 68: 8\n",
      "Case 69: 49\n",
      "Case 70: 3\n",
      "Case 71: 20\n",
      "Case 72: 34\n",
      "Case 73: 36\n",
      "Case 74: 48\n",
      "Case 75: 1248\n",
      "Case 76: 9500\n",
      "Case 77: 16\n",
      "Case 78: 2\n",
      "Case 79: 36\n",
      "Case 80: 98\n",
      "Case 81: 30\n",
      "Case 82: 44\n",
      "Case 83: 30\n",
      "Case 84: 7\n",
      "Case 85: 78\n",
      "Case 86: 2\n",
      "Case 87: 19\n",
      "Case 88: 2325\n",
      "Case 89: 13\n",
      "Case 90: 750\n",
      "Case 91: 12\n",
      "Case 92: 22\n",
      "Case 93: 20\n",
      "Case 94: 15\n",
      "Case 95: 20\n",
      "Case 96: 10\n",
      "Case 97: 50\n",
      "Case 98: 11\n",
      "Case 99: 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cases = [p.to_case() for p in load_gsm_eng()]\n",
    "\n",
    "for i, case in enumerate(cases):\n",
    "    print(f\"Case {i}: {re.search(r'####\\s*((\\d|,)+)', case.expected_output).group(1).replace(',', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729d50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8602a91b32240f3b2a2cce15bb61888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "cases = [p.to_case() for p in load_gsm_eng()]\n",
    "\n",
    "response_model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "agent_evaluated = HuggingFaceAgent(response_model_name, examples=cases[-3:], answer_pattern=answer_pattern)\n",
    "\n",
    "# Custom evaluator: compare only the answer after '####'\n",
    "@dataclass\n",
    "class AnswerOnlyMatch(Evaluator):\n",
    "    def evaluate(self, ctx: EvaluatorContext) -> bool:\n",
    "        # Extract answer after '####' using regex\n",
    "        m_pred = re.search(r\"####\\s*((\\d|,)+)\", ctx.output)\n",
    "        m_true = re.search(r\"####\\s*((\\d|,)+)\", ctx.expected_output)\n",
    "        if not m_pred or not m_true:\n",
    "            return False\n",
    "        return float(m_pred.group(1).replace(\",\",\"\")) == float(m_true.group(1).replace(\",\",\"\"))\n",
    "\n",
    "ds = Dataset(\n",
    "    cases=cases[:2],\n",
    "    evaluators=[AnswerOnlyMatch()],\n",
    ")\n",
    "\n",
    "async def answer_question(question: str) -> str:\n",
    "    r = agent_evaluated.run(question)\n",
    "    return r\n",
    "\n",
    "report = ds.evaluate_sync(answer_question)\n",
    "report.print(include_input=True, include_output=True, include_expected_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "209d5cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case(name='1275', inputs=\"John's car breaks down. The car weighs 1200 pounds and he has luggage in it weighing 250 pounds. He also has his two young children who weigh 75 pounds each in it. If the force to move the car is 1% of the weight, how much force does he need to push the car?\", metadata={'filepath': '/work/m-gsm-symbolic/data/templates/eng/symbolic/0067.json'}, expected_output='His two children weigh 75*2=<<75*2=150>>150 pounds\\nSo the total weight of the car and everything is 1200+250+150=<<1200+250+150=1600>>1600 pounds\\nSo he needs to generate 1600*0.01=<<1600*0.01=16>>16 pounds\\n#### 16', evaluators=[])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] WON'T CONVERT _apply_token_bitmask_inplace_kernel /work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines_core/kernels/torch.py line 43 \n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] due to: \n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1213, in __call__\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 598, in __call__\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return _compile(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1059, in _compile\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_utils_internal.py\", line 97, in wrapper_function\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 761, in compile_inner\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 797, in _compile_inner\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 257, in _fn\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in transform\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     tracer.run()\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3498, in run\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     super().run()\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1337, in run\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     while self.step():\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]           ^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1246, in step\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 819, in wrapper\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return inner_fn(self, inst)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2931, in CALL\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self._call(inst)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2925, in _call\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self.call_function(fn, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1170, in call_function\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py\", line 913, in call_function\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return self.obj.call_method(tx, self.name, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py\", line 632, in call_method\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return wrap_fx_proxy(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py\", line 2302, in wrap_fx_proxy\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py\", line 2368, in wrap_fx_proxy_cls\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return _wrap_fx_proxy(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py\", line 2464, in _wrap_fx_proxy\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3229, in get_fake_value\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3127, in get_fake_value\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     ret_val = wrap_fake_exception(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]               ^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 2641, in wrap_fake_exception\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return fn()\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3128, in <lambda>\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     lambda: run_node(tx.output, node, args, kwargs, nnmodule)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3325, in run_node\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     raise RuntimeError(make_error_message(e)).with_traceback(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3295, in run_node\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return getattr(args[0], node.target)(*args[1:], **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/utils/_stats.py\", line 27, in wrapper\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 1282, in __torch_dispatch__\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return self.dispatch(func, types, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 1823, in dispatch\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 1393, in _cached_dispatch_impl\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2435, in _dispatch_impl\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self.wrap_meta_outputs_with_default_device_logic(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2562, in wrap_meta_outputs_with_default_device_logic\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return tree_map(wrap, r)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py\", line 1145, in tree_map\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return treespec.unflatten(map(func, *flat_args))\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py\", line 982, in unflatten\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     leaves = list(leaves)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]              ^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2540, in wrap\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     ) = FakeTensor._find_common_device(func, flat_args)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 896, in _find_common_device\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     merge_devices(arg)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 891, in merge_devices\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     raise RuntimeError(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] torch._dynamo.exc.TorchRuntimeError: Dynamo failed to run FX node with fake tensors: call_method masked_fill_(*(FakeTensor(..., device='cuda:0', size=(1, s1)), FakeTensor(..., size=(1, s1), dtype=torch.bool), -inf), **{}): got RuntimeError('Unhandled FakeTensor Device Propagation for aten.masked_fill_.Scalar, found two different devices cuda:0, cpu')\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] \n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] from user code:\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]    File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines_core/kernels/torch.py\", line 64, in _apply_token_bitmask_inplace_kernel\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     logits.masked_fill_(~bit_masks, -torch.inf)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] \n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] \n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1213, in __call__\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 598, in __call__\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return _compile(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1059, in _compile\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_utils_internal.py\", line 97, in wrapper_function\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 761, in compile_inner\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 797, in _compile_inner\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 257, in _fn\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in transform\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     tracer.run()\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3498, in run\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     super().run()\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1337, in run\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     while self.step():\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]           ^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1246, in step\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 819, in wrapper\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return inner_fn(self, inst)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2931, in CALL\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self._call(inst)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2925, in _call\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self.call_function(fn, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1170, in call_function\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py\", line 913, in call_function\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return self.obj.call_method(tx, self.name, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py\", line 632, in call_method\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return wrap_fx_proxy(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py\", line 2302, in wrap_fx_proxy\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py\", line 2368, in wrap_fx_proxy_cls\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return _wrap_fx_proxy(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py\", line 2464, in _wrap_fx_proxy\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3229, in get_fake_value\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3127, in get_fake_value\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     ret_val = wrap_fake_exception(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]               ^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 2641, in wrap_fake_exception\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return fn()\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3128, in <lambda>\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     lambda: run_node(tx.output, node, args, kwargs, nnmodule)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3325, in run_node\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     raise RuntimeError(make_error_message(e)).with_traceback(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 3295, in run_node\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return getattr(args[0], node.target)(*args[1:], **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/utils/_stats.py\", line 27, in wrapper\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 1282, in __torch_dispatch__\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return self.dispatch(func, types, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 1823, in dispatch\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 1393, in _cached_dispatch_impl\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2435, in _dispatch_impl\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     self.wrap_meta_outputs_with_default_device_logic(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2562, in wrap_meta_outputs_with_default_device_logic\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return tree_map(wrap, r)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py\", line 1145, in tree_map\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     return treespec.unflatten(map(func, *flat_args))\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py\", line 982, in unflatten\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     leaves = list(leaves)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]              ^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2540, in wrap\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     ) = FakeTensor._find_common_device(func, flat_args)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 896, in _find_common_device\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     merge_devices(arg)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]   File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 891, in merge_devices\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     raise RuntimeError(\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] torch._dynamo.exc.TorchRuntimeError: Dynamo failed to run FX node with fake tensors: call_method masked_fill_(*(FakeTensor(..., device='cuda:0', size=(1, s1)), FakeTensor(..., size=(1, s1), dtype=torch.bool), -inf), **{}): got RuntimeError('Unhandled FakeTensor Device Propagation for aten.masked_fill_.Scalar, found two different devices cuda:0, cpu')\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] \n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] from user code:\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]    File \"/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines_core/kernels/torch.py\", line 64, in _apply_token_bitmask_inplace_kernel\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280]     logits.masked_fill_(~bit_masks, -torch.inf)\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] \n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0806 13:52:36.266000 12441 torch/_dynamo/convert_frame.py:1280] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected self and mask to be on the same device, but got mask on cpu and self on cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m cases[:\u001b[32m2\u001b[39m]:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(case)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43magent_evaluated\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcase\u001b[49m\u001b[43m.\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mHuggingFaceAgent.run\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     43\u001b[39m     prompt = \u001b[38;5;28mself\u001b[39m._build_prompt(prompt)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     model_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines/models/base.py:122\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, model_input, output_type, backend, **inference_kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call the model.\u001b[39;00m\n\u001b[32m     88\u001b[39m \n\u001b[32m     89\u001b[39m \u001b[33;03mUsers can call the model directly, in which case we will create a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    118\u001b[39m \n\u001b[32m    119\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moutlines\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Generator\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines/generator.py:297\u001b[39m, in \u001b[36mSteerableGenerator.__call__\u001b[39m\u001b[34m(self, prompt, **inference_kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.logits_processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m.logits_processor.reset()\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minference_kwargs\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines/models/transformers.py:307\u001b[39m, in \u001b[36mTransformers.generate\u001b[39m\u001b[34m(self, model_input, output_type, **inference_kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m prompts, inputs = \u001b[38;5;28mself\u001b[39m._prepare_model_inputs(model_input, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    305\u001b[39m logits_processor = \u001b[38;5;28mself\u001b[39m.type_adapter.format_output_type(output_type)\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m generated_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_output_seq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# required for multi-modal models that return a 2D tensor even when\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[38;5;66;03m# num_return_sequences is 1\u001b[39;00m\n\u001b[32m    316\u001b[39m num_samples = inference_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mnum_return_sequences\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines/models/transformers.py:356\u001b[39m, in \u001b[36mTransformers._generate_output_seq\u001b[39m\u001b[34m(self, prompts, inputs, **inference_kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_output_seq\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompts, inputs, **inference_kwargs):\n\u001b[32m    354\u001b[39m     input_ids = inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m     \u001b[38;5;66;03m# encoder-decoder returns output_ids only, decoder-only returns full seq ids\u001b[39;00m\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.config.is_encoder_decoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2634\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2626\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2627\u001b[39m         input_ids=input_ids,\n\u001b[32m   2628\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2629\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2630\u001b[39m         **model_kwargs,\n\u001b[32m   2631\u001b[39m     )\n\u001b[32m   2633\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2634\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2645\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2646\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2647\u001b[39m         input_ids=input_ids,\n\u001b[32m   2648\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2649\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2650\u001b[39m         **model_kwargs,\n\u001b[32m   2651\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3634\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3631\u001b[39m next_token_logits = outputs.logits[:, -\u001b[32m1\u001b[39m, :].to(copy=\u001b[38;5;28;01mTrue\u001b[39;00m, dtype=torch.float32, device=input_ids.device)\n\u001b[32m   3633\u001b[39m \u001b[38;5;66;03m# pre-process distribution\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3634\u001b[39m next_token_scores = \u001b[43mlogits_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_token_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3636\u001b[39m \u001b[38;5;66;03m# Store scores, attentions and hidden_states when required\u001b[39;00m\n\u001b[32m   3637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:93\u001b[39m, in \u001b[36mLogitsProcessorList.__call__\u001b[39m\u001b[34m(self, input_ids, scores, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         scores = processor(input_ids, scores, **kwargs)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m         scores = \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines/processors/base_logits_processor.py:123\u001b[39m, in \u001b[36mOutlinesLogitsProcessor.__call__\u001b[39m\u001b[34m(self, input_ids, logits)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# Guarantee passed as 2D Tensors, then covert back to original\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# (1D or 2D) shape\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.tensor_adapter.shape(logits)) == \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     processed_logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.tensor_adapter.shape(logits)) == \u001b[32m1\u001b[39m:\n\u001b[32m    125\u001b[39m     processed_logits = \u001b[38;5;28mself\u001b[39m.tensor_adapter.squeeze(\n\u001b[32m    126\u001b[39m         \u001b[38;5;28mself\u001b[39m.process_logits(\n\u001b[32m    127\u001b[39m             \u001b[38;5;28mself\u001b[39m.tensor_adapter.unsqueeze(input_ids),\n\u001b[32m    128\u001b[39m             \u001b[38;5;28mself\u001b[39m.tensor_adapter.unsqueeze(logits),\n\u001b[32m    129\u001b[39m         ),\n\u001b[32m    130\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines/backends/outlines_core.py:172\u001b[39m, in \u001b[36mOutlinesCoreLogitsProcessor.process_logits\u001b[39m\u001b[34m(self, input_ids, logits)\u001b[39m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guides[i].is_finished():\n\u001b[32m    167\u001b[39m             \u001b[38;5;28mself\u001b[39m._guides[i].advance(\n\u001b[32m    168\u001b[39m                 token_id=last_token_id,\n\u001b[32m    169\u001b[39m                 return_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    170\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines/backends/outlines_core.py:114\u001b[39m, in \u001b[36mOutlinesCoreLogitsProcessor._bias_logits_torch\u001b[39m\u001b[34m(self, batch_size, logits)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[32m    113\u001b[39m     fill_next_token_bitmask(\u001b[38;5;28mself\u001b[39m._guides[i], \u001b[38;5;28mself\u001b[39m._bitmasks[i])\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[43mapply_token_bitmask_inplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensor_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bitmasks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines_core/kernels/torch.py:104\u001b[39m, in \u001b[36mapply_token_bitmask_inplace\u001b[39m\u001b[34m(logits, mask)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mask.shape[\u001b[32m0\u001b[39m] != logits.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    102\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid batch size: Expected `mask.shape[0]` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) to match `logits.shape[0]` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    103\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43m_apply_token_bitmask_inplace_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:655\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    652\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/m-gsm-symbolic/.venv/lib/python3.12/site-packages/outlines_core/kernels/torch.py:64\u001b[39m, in \u001b[36m_apply_token_bitmask_inplace_kernel\u001b[39m\u001b[34m(logits, mask)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Unpack mask so each bit is a boolean\u001b[39;00m\n\u001b[32m     51\u001b[39m bit_masks = (\n\u001b[32m     52\u001b[39m     (\n\u001b[32m     53\u001b[39m         torch.bitwise_right_shift(\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     .narrow(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, logits.shape[\u001b[32m1\u001b[39m])\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43mlogits\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m~\u001b[49m\u001b[43mbit_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43minf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: expected self and mask to be on the same device, but got mask on cpu and self on cuda:0"
     ]
    }
   ],
   "source": [
    "cases = [p.to_case() for p in load_gsm_eng()]\n",
    "response_model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "agent_evaluated = HuggingFaceAgent(response_model_name, examples=cases[-3:], answer_pattern=answer_pattern)\n",
    "\n",
    "for case in cases[:2]:\n",
    "    print(case)\n",
    "    print(agent_evaluated.run(case.inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d754afea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device\n",
    "model.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c097bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\", torch_dtype=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56655ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3474a8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Case(name='728', inputs='Candy has 15 light blue spools of thread, 45 dark blue spools of thread, 40 light green spools of thread, and 50 dark green spools of thread. What percent of her spools are blue?', metadata={'filepath': '/home/au338890/repos/m-gsm-symbolic/data/templates/eng/symbolic/0066.json'}, expected_output='First find the number of blue spools: 15 spools + 45 spools = <<15+45=60>>60 spools\\nThen find the total number of spools: 40 spools + 50 spools + 60 spools = <<40+50+60=150>>150 spools\\nThen divide the number of blue spools by the total number of spools and multiply by 100% to express the answer as a percentage: 60 spools / 150 spools * 100% = 40%\\n#### 40', evaluators=[])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b61d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_evaluated = HuggingFaceAgent(response_model_name, examples=cases[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "393b0bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3672, in run_code\n",
      "  |     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |     ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/tmp/ipykernel_10327/1812324380.py\", line 5, in <module>\n",
      "  |     report_2 = ds.evaluate_sync(answer_question)\n",
      "  |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/dataset.py\", line 315, in evaluate_sync\n",
      "  |     return get_event_loop().run_until_complete(self.evaluate(task, name=name, max_concurrency=max_concurrency))\n",
      "  |            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "  |     return f.result()\n",
      "  |            ~~~~~~~~^^\n",
      "  |   File \"/home/au338890/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "  |     raise self._exception.with_traceback(self._exception_tb)\n",
      "  |   File \"/home/au338890/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py\", line 306, in __step_run_and_handle_result\n",
      "  |     result = coro.throw(exc)\n",
      "  |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/dataset.py\", line 283, in evaluate\n",
      "  |     cases=await task_group_gather(\n",
      "  |           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |     ...<4 lines>...\n",
      "  |     ),\n",
      "  |     ^\n",
      "  |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/_utils.py\", line 99, in task_group_gather\n",
      "  |     async with anyio.create_task_group() as tg:\n",
      "  |                ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  |         \"unhandled errors in a TaskGroup\", self._exceptions\n",
      "  |     ) from None\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (2 sub-exceptions)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/home/au338890/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    |     result = coro.send(None)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/_utils.py\", line 97, in _run_task\n",
      "    |     results[index] = await tsk()\n",
      "    |                      ^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/dataset.py\", line 279, in _handle_case\n",
      "    |     return await _run_task_and_evaluators(task, case, report_case_name, self.evaluators)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/dataset.py\", line 882, in _run_task_and_evaluators\n",
      "    |     scoring_context = await _run_task(task, case)\n",
      "    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/dataset.py\", line 820, in _run_task\n",
      "    |     task_output = await task(case.inputs)\n",
      "    |                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/tmp/ipykernel_10327/1812324380.py\", line 2, in answer_question\n",
      "    |     r = agent_evaluated.run(question)\n",
      "    |   File \"/tmp/ipykernel_10327/3741609218.py\", line 25, in run\n",
      "    |     model_output = self.model.generate(**model_input, max_new_tokens=500)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    |     return func(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/generation/utils.py\", line 2633, in generate\n",
      "    |     result = self._sample(\n",
      "    |         input_ids,\n",
      "    |     ...<5 lines>...\n",
      "    |         **model_kwargs,\n",
      "    |     )\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/generation/utils.py\", line 3614, in _sample\n",
      "    |     outputs = self(**model_inputs, return_dict=True)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    |     return self._call_impl(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    |     return forward_call(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/utils/generic.py\", line 961, in wrapper\n",
      "    |     output = func(self, *args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py\", line 460, in forward\n",
      "    |     outputs: BaseModelOutputWithPast = self.model(\n",
      "    |                                        ~~~~~~~~~~^\n",
      "    |         input_ids=input_ids,\n",
      "    |         ^^^^^^^^^^^^^^^^^^^^\n",
      "    |     ...<6 lines>...\n",
      "    |         **kwargs,\n",
      "    |         ^^^^^^^^^\n",
      "    |     )\n",
      "    |     ^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    |     return self._call_impl(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    |     return forward_call(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/utils/generic.py\", line 1069, in wrapper\n",
      "    |     outputs = func(self, *args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py\", line 390, in forward\n",
      "    |     hidden_states = decoder_layer(\n",
      "    |         hidden_states,\n",
      "    |     ...<5 lines>...\n",
      "    |         **kwargs,\n",
      "    |     )\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/modeling_layers.py\", line 94, in __call__\n",
      "    |     return super().__call__(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    |     return self._call_impl(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    |     return forward_call(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py\", line 289, in forward\n",
      "    |     hidden_states, _ = self.self_attn(\n",
      "    |                        ~~~~~~~~~~~~~~^\n",
      "    |         hidden_states=hidden_states,\n",
      "    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |     ...<6 lines>...\n",
      "    |         **kwargs,\n",
      "    |         ^^^^^^^^^\n",
      "    |     )\n",
      "    |     ^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    |     return self._call_impl(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    |     return forward_call(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py\", line 248, in forward\n",
      "    |     attn_output, attn_weights = attention_interface(\n",
      "    |                                 ~~~~~~~~~~~~~~~~~~~^\n",
      "    |         self,\n",
      "    |         ^^^^^\n",
      "    |     ...<6 lines>...\n",
      "    |         **kwargs,\n",
      "    |         ^^^^^^^^^\n",
      "    |     )\n",
      "    |     ^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/integrations/sdpa_attention.py\", line 81, in sdpa_attention_forward\n",
      "    |     attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "    |         query,\n",
      "    |     ...<6 lines>...\n",
      "    |         **sdpa_kwargs,\n",
      "    |     )\n",
      "    | RuntimeError: [enforce fail at alloc_cpu.cpp:119] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 35004463232 bytes. Error code 12 (Cannot allocate memory)\n",
      "    +---------------- 2 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/home/au338890/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    |     result = coro.send(None)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/_utils.py\", line 97, in _run_task\n",
      "    |     results[index] = await tsk()\n",
      "    |                      ^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/dataset.py\", line 279, in _handle_case\n",
      "    |     return await _run_task_and_evaluators(task, case, report_case_name, self.evaluators)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/dataset.py\", line 882, in _run_task_and_evaluators\n",
      "    |     scoring_context = await _run_task(task, case)\n",
      "    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/pydantic_evals/dataset.py\", line 820, in _run_task\n",
      "    |     task_output = await task(case.inputs)\n",
      "    |                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/tmp/ipykernel_10327/1812324380.py\", line 2, in answer_question\n",
      "    |     r = agent_evaluated.run(question)\n",
      "    |   File \"/tmp/ipykernel_10327/3741609218.py\", line 25, in run\n",
      "    |     model_output = self.model.generate(**model_input, max_new_tokens=500)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    |     return func(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/generation/utils.py\", line 2633, in generate\n",
      "    |     result = self._sample(\n",
      "    |         input_ids,\n",
      "    |     ...<5 lines>...\n",
      "    |         **model_kwargs,\n",
      "    |     )\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/generation/utils.py\", line 3614, in _sample\n",
      "    |     outputs = self(**model_inputs, return_dict=True)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    |     return self._call_impl(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    |     return forward_call(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/utils/generic.py\", line 961, in wrapper\n",
      "    |     output = func(self, *args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py\", line 460, in forward\n",
      "    |     outputs: BaseModelOutputWithPast = self.model(\n",
      "    |                                        ~~~~~~~~~~^\n",
      "    |         input_ids=input_ids,\n",
      "    |         ^^^^^^^^^^^^^^^^^^^^\n",
      "    |     ...<6 lines>...\n",
      "    |         **kwargs,\n",
      "    |         ^^^^^^^^^\n",
      "    |     )\n",
      "    |     ^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    |     return self._call_impl(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    |     return forward_call(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/utils/generic.py\", line 1069, in wrapper\n",
      "    |     outputs = func(self, *args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py\", line 390, in forward\n",
      "    |     hidden_states = decoder_layer(\n",
      "    |         hidden_states,\n",
      "    |     ...<5 lines>...\n",
      "    |         **kwargs,\n",
      "    |     )\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/modeling_layers.py\", line 94, in __call__\n",
      "    |     return super().__call__(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    |     return self._call_impl(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    |     return forward_call(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py\", line 289, in forward\n",
      "    |     hidden_states, _ = self.self_attn(\n",
      "    |                        ~~~~~~~~~~~~~~^\n",
      "    |         hidden_states=hidden_states,\n",
      "    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |     ...<6 lines>...\n",
      "    |         **kwargs,\n",
      "    |         ^^^^^^^^^\n",
      "    |     )\n",
      "    |     ^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    |     return self._call_impl(*args, **kwargs)\n",
      "    |            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    |     return forward_call(*args, **kwargs)\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py\", line 248, in forward\n",
      "    |     attn_output, attn_weights = attention_interface(\n",
      "    |                                 ~~~~~~~~~~~~~~~~~~~^\n",
      "    |         self,\n",
      "    |         ^^^^^\n",
      "    |     ...<6 lines>...\n",
      "    |         **kwargs,\n",
      "    |         ^^^^^^^^^\n",
      "    |     )\n",
      "    |     ^\n",
      "    |   File \"/home/au338890/repos/m-gsm-symbolic/.venv/lib/python3.13/site-packages/transformers/integrations/sdpa_attention.py\", line 81, in sdpa_attention_forward\n",
      "    |     attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "    |         query,\n",
      "    |     ...<6 lines>...\n",
      "    |         **sdpa_kwargs,\n",
      "    |     )\n",
      "    | RuntimeError: [enforce fail at alloc_cpu.cpp:119] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 35148549248 bytes. Error code 12 (Cannot allocate memory)\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "async def answer_question(question: str) -> str:\n",
    "    r = agent_evaluated.run(question)\n",
    "    return r\n",
    "\n",
    "report_2 = ds.evaluate_sync(answer_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ff9ec58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mreport_2\u001b[49m.print(include_input=\u001b[38;5;28;01mTrue\u001b[39;00m, include_output=\u001b[38;5;28;01mTrue\u001b[39;00m, include_expected_output=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'report_2' is not defined"
     ]
    }
   ],
   "source": [
    "report_2.print(include_input=True, include_output=True, include_expected_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f208c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4517bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hvis hver pirat svarede sandt til den givne opgave, skal et antal mnter, der er tilfldigt resulterer i et antal mnter, der er lik 30.\n",
      "I et ufuldstndigt skattecontainer, skal du vurdere, hvor mange mnter, der er i containeren, der er i den rigtige mnter.\n",
      "Antallet af mnter, der er i den rigtige mnter, er 10.\n",
      "\n",
      "Fr du tager beslutningen, skal du udfre en fejlfindende analyse.\n",
      "Tlle alle mnterne i containeren, der er i den rigtige mnter.\n",
      "Antallet af mnter, der er i den rigtige mnter, er 10.\n",
      "Der er 6 mnter, der er i den rigtige mnter.\n",
      "Antallet af mnter, der er i den rigtige mnter, er 10.\n",
      "Antallet af mnter, der er i den rigtige mnter, er 10.\n",
      "\n",
      "Det er ikke sandt, at der er 10 mnter i den rigtige mnter.\n",
      "Antallet af mnter i den rigtige mnter er 10.\n",
      "For at bestemme, hvor mange mnter, der er i den rigtige mnter, er det mest almindelige.\n",
      "Tll alle mnterne, der er i containeren, der er i den rigtige mnter.\n",
      "|     | Gold | Silver | Bronze |\n",
      "| Tom |   9   |   11   |   12   |\n",
      "| Al  |  7   |   10   |   10   |\n",
      "| Pit |  10  |   10   |   10   |\n",
      "| Jim |  9   |   10   |   10   |\n",
      "\n",
      "|     | Gold | Silver | Bronze |\n",
      "| Tom |   9   |   11   |   12   |\n",
      "| Al  |  7   |   10   |   10   |\n",
      "| Pit |  10  |   10   |   10   \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b922864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output does not provide the correct solution to the problem. It repeats incorrect numbers for the coins and does not solve the logic puzzle based on the condition given (only one pirate tells the truth).\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0].assertion_reason)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m-gsm-symbolic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
